{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c560c76e",
   "metadata": {},
   "source": [
    "# **Dataset Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbbab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('C:/Users/nextn/Downloads/Git/demand_prediction/data/raw/retail_store_inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e93a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Store ID', 'Product ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392175d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={'Inventory Level': 'Inventory', 'Units Sold': 'Sales',\n",
    "                                  'Units Ordered': 'Order', 'Demand Forecast': 'Demand',\n",
    "                                  'Weather Condition': 'Weather', 'Holiday/Promotion': 'Promotion',\n",
    "                                  'Competitor Pricing': 'Competitor Price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ac8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Date'] = pd.to_datetime(dataset['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d808e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Year'] = dataset['Date'].dt.year\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "dataset['Day'] = dataset['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1192a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf6753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['Category', 'Region', 'Weather', 'Seasonality'], drop_first=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff307464",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nextn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m      2\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m      3\u001b[0m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n",
      "File \u001b[1;32mc:\\Users\\nextn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\nextn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "dataset['Year'] = dataset['Date'].dt.year\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "dataset['Day'] = dataset['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14652a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18867f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE\n",
    "dataset = pd.get_dummies(dataset, columns=['Category', 'Region', 'Weather', 'Seasonality'], drop_first=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bed9a1",
   "metadata": {},
   "source": [
    "# **Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('Demand', axis=1)\n",
    "y = dataset['Demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cfa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X.keys())\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Original number of features: {X_scaled.shape[1]}\")\n",
    "print(f\"Number of components after PCA: {X_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf821edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Original number of features: {X_scaled.shape[1]}\")\n",
    "print(f\"Number of components after PCA: {X_pca.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f643d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff45b2",
   "metadata": {},
   "source": [
    "1. **SVR**\n",
    "\n",
    "$$\n",
    "\\hat{y}(x) = \\sum_{i=1}^{n} (\\alpha_i - \\alpha_i^*) K(x_i, x) + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# Train\n",
    "svr_model = SVR(kernel='rbf')\n",
    "svr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred_svr = svr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# Calculate metrics\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "# Print results\n",
    "print(\"SVR Results:\")\n",
    "print(\"MSE:\", mse_svr)\n",
    "print(\"RMSE:\", rmse_svr)\n",
    "print(\"MAE:\", mae_svr)\n",
    "print(\"R-squared:\", r2_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validation\n",
    "cv_rmse_gb = cross_val_score(svr_model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cv_rmse_mean_gb = np.mean(np.abs(cv_rmse_gb))\n",
    "cv_rmse_std_gb = np.std(np.abs(cv_rmse_gb))\n",
    "print(f\"Cross-validation RMSE: {cv_rmse_mean_gb} ± {cv_rmse_std_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e132fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define a function to plot learning curves with MSE, RMSE, R², and MAE\n",
    "def plot_learning_curve(estimator, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    # Compute learning curves for MSE\n",
    "    train_sizes, train_scores_mse, val_scores_mse = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes, scoring='neg_mean_squared_error'\n",
    "    )\n",
    "\n",
    "    # Convert negative MSE to positive MSE\n",
    "    train_scores_mse = -train_scores_mse\n",
    "    val_scores_mse = -val_scores_mse\n",
    "\n",
    "    # Compute RMSE from MSE\n",
    "    train_scores_rmse = np.sqrt(train_scores_mse)\n",
    "    val_scores_rmse = np.sqrt(val_scores_mse)\n",
    "\n",
    "    # Compute learning curves for R²\n",
    "    train_sizes, train_scores_r2, val_scores_r2 = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes, scoring='r2'\n",
    "    )\n",
    "\n",
    "    # Compute learning curves for MAE\n",
    "    train_sizes, train_scores_mae, val_scores_mae = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "\n",
    "    # Convert negative MAE to positive MAE\n",
    "    train_scores_mae = -train_scores_mae\n",
    "    val_scores_mae = -val_scores_mae\n",
    "\n",
    "    # Calculate mean and standard deviation for all metrics\n",
    "    metrics = {\n",
    "        \"MSE\": (train_scores_mse, val_scores_mse),\n",
    "        \"RMSE\": (train_scores_rmse, val_scores_rmse),\n",
    "        \"R²\": (train_scores_r2, val_scores_r2),\n",
    "        \"MAE\": (train_scores_mae, val_scores_mae)\n",
    "    }\n",
    "\n",
    "    means_stds = {metric: (np.mean(train, axis=1), np.std(train, axis=1),\n",
    "                           np.mean(val, axis=1), np.std(val, axis=1))\n",
    "                  for metric, (train, val) in metrics.items()}\n",
    "\n",
    "    # Plot the learning curves\n",
    "    plt.figure(figsize=(30, 8))\n",
    "\n",
    "    metric_titles = {\n",
    "        \"MSE\": \"Mean Squared Error (MSE)\",\n",
    "        \"RMSE\": \"Root Mean Squared Error (RMSE)\",\n",
    "        \"R²\": \"R-squared (R²)\",\n",
    "        \"MAE\": \"Mean Absolute Error (MAE)\"\n",
    "    }\n",
    "\n",
    "    colors = {\"train\": 'r', \"val\": 'g'}\n",
    "\n",
    "    for i, (metric, (train_mean, train_std, val_mean, val_std)) in enumerate(means_stds.items()):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.plot(train_sizes, train_mean, 'o-', color=colors[\"train\"], label=f'Training {metric}')\n",
    "        plt.plot(train_sizes, val_mean, 'o-', color=colors[\"val\"], label=f'Validation {metric}')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=colors[\"train\"])\n",
    "        plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color=colors[\"val\"])\n",
    "        plt.xlabel('Training Set Size')\n",
    "        plt.ylabel(metric_titles[metric])\n",
    "        plt.title(f'{metric_titles[metric]} Learning Curve for {type(estimator).__name__}')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the Learning Curve including MAE\n",
    "plot_learning_curve(svr_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_lime(estimator, X_train_scaled, X_test_scaled, feature_names, num_features=5, instance_index=0):\n",
    "    # Initialize LIME explainer\n",
    "    explainer = LimeTabularExplainer(\n",
    "        X_train_scaled,\n",
    "        feature_names=feature_names,\n",
    "        mode=\"regression\"\n",
    "    )\n",
    "\n",
    "    # Select the specified instance from the test set for explanation\n",
    "    instance = X_test_scaled[instance_index]\n",
    "\n",
    "    # Explain the prediction for the selected instance\n",
    "    exp = explainer.explain_instance(instance, estimator.predict, num_features=num_features)\n",
    "\n",
    "    # Print textual explanation for context\n",
    "    print(f\"LIME Output for {type(estimator).__name__} Model:\")\n",
    "    print(f\"Prediction: {estimator.predict(instance.reshape(1, -1))[0]:.4f}\")\n",
    "    print(\"\\nTop Contributing Features:\")\n",
    "    for feature, contribution in exp.as_list():\n",
    "        print(f\"{feature}: {contribution:.4f}\")\n",
    "\n",
    "    # Display explanation in notebook\n",
    "    exp.show_in_notebook(show_table=True)\n",
    "\n",
    "    # Customize and display Matplotlib plot\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    fig.set_size_inches(8, 6)\n",
    "    plt.title(f\"LIME Explanation for Test Instance {instance_index + 1}\", fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(\"Feature Contribution to Prediction\", fontsize=12)\n",
    "    plt.ylabel(\"Feature\", fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the LIME visualization function\n",
    "visualize_lime(svr_model, X_train, X_test, feature_names, num_features=10, instance_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370adb76",
   "metadata": {},
   "source": [
    "2. **MLP Regressor**\n",
    "$$\n",
    "\\hat{y} = f_{\\text{out}}\\left( \\sum_{j=1}^{H} w_j^{(2)} \\cdot f_{\\text{act}}\\left( \\sum_{i=1}^{d} w_{ji}^{(1)} x_i + b_j^{(1)} \\right) + b^{(2)} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "# Train\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, early_stopping=True, validation_fraction=0.1, random_state=42)\n",
    "mlp_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0162465",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = mlp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89983b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "rmse_mlp = np.sqrt(mse_mlp)\n",
    "mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
    "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "# Print results\n",
    "print(\"MLP Results:\")\n",
    "print(\"MSE:\", mse_mlp)\n",
    "print(\"RMSE:\", rmse_mlp)\n",
    "print(\"MAE:\", mae_mlp)\n",
    "print(\"R-squared:\", r2_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc90e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_rmse_mlp = cross_val_score(mlp_model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cv_rmse_mean_mlp = np.mean(np.abs(cv_rmse_mlp))\n",
    "cv_rmse_std_mlp = np.std(np.abs(cv_rmse_mlp))\n",
    "\n",
    "print(f\"Cross-validation RMSE: {cv_rmse_mean_mlp} ± {cv_rmse_std_mlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "plot_learning_curve(mlp_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the trained model and test data\n",
    "visualize_lime(mlp_model, X_train, X_test, feature_names, num_features=10, instance_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f7f5a",
   "metadata": {},
   "source": [
    "3. **KNN Regressor**\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x}) = \\frac{1}{k} \\sum_{i \\in \\mathcal{N}_k(\\mathbf{x})} y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Training\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac50f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "rmse_knn = np.sqrt(mse_knn)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(\"KNN Results:\")\n",
    "print(\"MSE:\", mse_knn)\n",
    "print(\"RMSE:\", rmse_knn)\n",
    "print(\"MAE:\", mae_knn)\n",
    "print(\"R-squared:\", r2_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8174005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_rmse_knn = cross_val_score(knn_model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cv_rmse_mean_knn = np.mean(np.abs(cv_rmse_knn))\n",
    "cv_rmse_std_knn = np.std(np.abs(cv_rmse_knn))\n",
    "\n",
    "print(f\"Cross-validation RMSE: {cv_rmse_mean_knn} ± {cv_rmse_std_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1eb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "plot_learning_curve(knn_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the trained model and test data\n",
    "visualize_lime(knn_model, X_train, X_test, feature_names, num_features=10, instance_index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
